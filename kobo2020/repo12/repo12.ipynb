{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhDaSWmF3YuX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "880edc4f-ddec-4f61-d9a8-07c101330904"
      },
      "source": [
        "!wget http://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
        "!tar xfz ldcc-20140209.tar.gz\n",
        "\n",
        "category2id = {\"kaden-channel\":0, \"peachy\":1, \"sports-watch\":2, \"dokujo-tsushin\":3, \"livedoor-homme\":4, \"it-life-hack\":5, \"movie-enter\":6}\n",
        "\n",
        "# Livedoorニュースコーパスからテキスト分類用のデータを作成．\n",
        "import glob\n",
        "import random\n",
        "\n",
        "# 1行は [文][TAB][ラベル]からなる\n",
        "write_lines = []\n",
        "for d in category2id.keys():\n",
        "  for file in glob.glob(\"text/\" + d + \"/*.txt\"):\n",
        "    with open(file) as f:\n",
        "      lines = f.readlines()\n",
        "      # 最初の2行はURLと日付なので捨てる\n",
        "      for line in lines[3:]:\n",
        "        line = line.strip()\n",
        "        if len(line) > 20 and len(line) < 256 and \"http\" not in line:\n",
        "          write_lines.append(line + \"\\t\" + str(category2id[d]) + \"\\n\")\n",
        "\n",
        "random.shuffle(write_lines)\n",
        "# Train, Dev, Testの3つに分ける.\n",
        "dev = write_lines[0:2000]\n",
        "test =write_lines[2000:4000]\n",
        "train = write_lines[4000:]\n",
        "# ファイルに保存\n",
        "w = open(\"train.tsv\", \"w\")\n",
        "w.writelines(train)\n",
        "w.close()\n",
        "w = open(\"dev.tsv\", \"w\")\n",
        "w.writelines(dev)\n",
        "w.close()\n",
        "w = open(\"test.tsv\", \"w\")\n",
        "w.writelines(test)\n",
        "w.close()\n",
        "print(\"data size \", len(train), len(dev), len(test))\n",
        "\n",
        "!head dev.tsv\n",
        "\n",
        "#83.pyが使える"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-23 12:26:22--  http://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Resolving www.rondhuit.com (www.rondhuit.com)... 59.106.19.174\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:80... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://www.rondhuit.com/download/ldcc-20140209.tar.gz [following]\n",
            "--2020-08-23 12:26:23--  https://www.rondhuit.com/download/ldcc-20140209.tar.gz\n",
            "Connecting to www.rondhuit.com (www.rondhuit.com)|59.106.19.174|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8855190 (8.4M) [application/x-gzip]\n",
            "Saving to: ‘ldcc-20140209.tar.gz.1’\n",
            "\n",
            "ldcc-20140209.tar.g 100%[===================>]   8.44M  1.86MB/s    in 5.4s    \n",
            "\n",
            "2020-08-23 12:26:29 (1.57 MB/s) - ‘ldcc-20140209.tar.gz.1’ saved [8855190/8855190]\n",
            "\n",
            "data size  67653 2000 2000\n",
            "・【話題】誰もがスマホに持つ不満はやっぱりあれ！　対策法は？\t0\n",
            "6月1日から、R.NEWBOLD代官山店、大阪堀江店をメインに6店舗で、「LOVE ENGLAND 2010展」を開催。イングランド代表チームの歴代ユニフォームや写真などが掲出されるほか、腕時計、Tシャツ、ポロシャツなどのコラボレーショングッズを販売する。\t4\n",
            "「いろいろな年代がいる組織の中で働いていると、『年代やキャリアによって、仕事の仕方は変えていかないといけない』とつくづく思いますね」。\t3\n",
            "・Androidアップデートは何が重要か? OSのアップデートよりも重要な事\t5\n",
            "「最高の人生の終わり方〜エンディングプランナー〜」は視聴率を回復させることができるのか、そして前田敦子は自信を取り戻すことができるのか、多いに注目だ。\t0\n",
            "別注したムートン貼りのAVラックは、通称「メリーさん」。ついつい触りたくなる質感が絶妙だ。\t4\n",
            "ドラマ『クリミナル・マインド／FBI vs. 異常犯罪』のマニアにとっては、この導入はある意味定石とも言えるのかもしれないが、やはりシーズン5を語るにはここから話を始めたい。そう、第9話（通算100話目）「死神との決着」の冒頭で用いられた、この一節である。\t6\n",
            "・映画『ラビット・ホラー3D』- 作品情報\t6\n",
            "彼氏や家族と過ごす幸せそうな同僚や友人達を尻目に、理想のデートを思い抱きつつ、それでも、独り身の仲間同士で飲み会をしてみたり、意中の男性をなんとか誘い出そうと躍起になってみたり——。中には一人部屋で寛いでいる方がよっぽど和むという割り切った独女だっている筈だ。\t3\n",
            "どうもタバス子と申します。よろしくお願いいたします。\t4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vPbdxQE36jV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "86d2714d-f306-4092-8cf4-5219ba4a807b"
      },
      "source": [
        "!pip install transformers\n",
        "!apt install git make curl xz-utils file\n",
        "!apt install mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8\n",
        "!pip install mecab-python3==0.996.5\n",
        "\n",
        "import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "import transformers\n",
        "\n",
        "pretrained_model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "\n",
        "# 事前学習済みモデルのトークナイザを使用\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model_name)\n",
        "#中でめかぶを使っている\n",
        "# 形態素解析 (内部でMeCabを使用)\n",
        "text1 = \"今日はいい天気だね\"\n",
        "text2 = \"明日は雨がふるかもしれませんね\"\n",
        "\n",
        "print(\"text1\", tokenizer.tokenize(text1))\n",
        "print(\"text2\", tokenizer.tokenize(text2))\n",
        "\n",
        "\"\"\"\n",
        "text1 ['今日', 'は', 'いい', '天気', 'だ', 'ね']\n",
        "text2 ['明日', 'は', '雨', 'が', 'ふる', 'かも', 'しれ', 'ませ', 'ん', 'ね']\n",
        "\"\"\"\n",
        "\n",
        "# BERTに入力する形式に変換　\n",
        "for_bert_inputs = tokenizer([text1, text2], padding=True, return_tensors=\"pt\")\n",
        "print(\"for_bert_inputs\", for_bert_inputs)\n",
        "\"\"\"\n",
        "for_bert_inputs {'input_ids': tensor([[    2,  3246,     9,  2575, 11385,    75,  1852,     3,     0,     0,\n",
        "             0,     0],\n",
        "        [    2, 11475,     9,  3741,    14,  8491,  4830,  6758,  6769,  1058,\n",
        "          1852,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
        "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
        "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
        "\"\"\"\n",
        "# input_ids: 単語をIDに変換した系列．padding済み\n",
        "# token_type_ids： 2文からなるペアを入力した場合に，1文目と2文目を区別するための系列\n",
        "# attention_mask： input_idsのpadding部分とそうでない部分を区別するための系列\n",
        "\n",
        "\n",
        "# 参考．文のペアを入れる場合の例\n",
        "text3 = \"そうかな\"\n",
        "text4 = \"違うと思います\"\n",
        "tmp = tokenizer([[text1, text2],[text3, text4]], padding=True, return_tensors=\"pt\")\n",
        "print(\"tmp\", tmp)\n",
        "\"\"\"\n",
        "tmp {'input_ids': tensor([[    2,  3246,     9,  2575, 11385,    75,  1852,     3, 11475,     9,\n",
        "          3741,    14,  8491,  4830,  6758,  6769,  1058,  1852,     3],\n",
        "        [    2,  1778,    29,    18,     3,  5720,    13,  2502,  2610,     3,\n",
        "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
        "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "# BERTの事前学習済みモデルをロード．BertForSequenceClassificationは1文が与えられて分類を行うクラス．num_labelsでラベル数を指定\n",
        "# 他にもいろいろ用意されている．使用例も書かれている→  https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=5)\n",
        "\n",
        "out = model(input_ids=for_bert_inputs[\"input_ids\"], token_type_ids=for_bert_inputs[\"token_type_ids\"], attention_mask=for_bert_inputs[\"attention_mask\"])\n",
        "print(for_bert_inputs[\"input_ids\"].shape)\n",
        "print(\"out\", out)\n",
        "\n",
        "model = transformers.BertModel.from_pretrained(pretrained_model_name)\n",
        "out = model(input_ids=for_bert_inputs[\"input_ids\"], token_type_ids=for_bert_inputs[\"token_type_ids\"], attention_mask=for_bert_inputs[\"attention_mask\"])\n",
        "# pooled_output = outputs[1]\n",
        "\n",
        "# pooled_output = self.dropout(pooled_output)\n",
        "# logits = self.classifier(pooled_output)\n",
        "print(\"out\", out[1].size())\n",
        "print(out[0], out[1])\n",
        "\"\"\"\n",
        "out (tensor([[-0.4694, -0.2888,  0.1584,  0.1443,  0.2474],\n",
        "        [-0.4795, -0.2614,  0.0915,  0.1614,  0.1209]],\n",
        "       grad_fn=<AddmmBackward>),)\n",
        "\"\"\"\n",
        "#線形層に通したものがでてくる\n",
        "# あとは損失を計算していつもどおりbackpropすればOK"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "make is already the newest version (4.1-9.1ubuntu1).\n",
            "xz-utils is already the newest version (5.2.2-1.3).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.9).\n",
            "file is already the newest version (1:5.32-2ubuntu0.4).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libmecab-dev is already the newest version (0.996-5).\n",
            "mecab is already the newest version (0.996-5).\n",
            "mecab-ipadic is already the newest version (2.7.0-20070801+main-1).\n",
            "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: mecab-python3==0.996.5 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n",
            "text1 ['今日', 'は', 'いい', '天気', 'だ', 'ね']\n",
            "text2 ['明日', 'は', '雨', 'が', 'ふる', 'かも', 'しれ', 'ませ', 'ん', 'ね']\n",
            "for_bert_inputs {'input_ids': tensor([[    2,  3246,     9,  2575, 11385,    75,  1852,     3,     0,     0,\n",
            "             0,     0],\n",
            "        [    2, 11475,     9,  3741,    14,  8491,  4830,  6758,  6769,  1058,\n",
            "          1852,     3]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
            "tmp {'input_ids': tensor([[    2,  3246,     9,  2575, 11385,    75,  1852,     3, 11475,     9,\n",
            "          3741,    14,  8491,  4830,  6758,  6769,  1058,  1852,     3],\n",
            "        [    2,  1778,    29,    18,     3,  5720,    13,  2502,  2610,     3,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
            "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]])}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 12])\n",
            "out (tensor([[-0.5546,  0.0767,  0.0210, -0.2505, -0.1633],\n",
            "        [-0.5298,  0.1092, -0.0563, -0.2727, -0.0979]],\n",
            "       grad_fn=<AddmmBackward>),)\n",
            "out torch.Size([2, 768])\n",
            "tensor([[[ 0.0775, -0.0378,  0.0342,  ..., -0.0456,  0.1380, -0.0157],\n",
            "         [ 0.2113,  0.3132, -0.6946,  ..., -0.1357,  0.0432, -0.0446],\n",
            "         [ 0.3533, -0.3380, -0.1323,  ...,  0.9686,  0.0417,  0.1601],\n",
            "         ...,\n",
            "         [ 0.0564,  0.1251,  0.0500,  ..., -0.0398,  0.1255, -0.2077],\n",
            "         [ 0.0572,  0.1707,  0.0400,  ..., -0.0136,  0.0938, -0.1160],\n",
            "         [ 0.0562, -0.0391, -0.0496,  ...,  0.0270,  0.0026, -0.0111]],\n",
            "\n",
            "        [[-0.0973,  0.3620, -0.2870,  ..., -0.1258,  0.1693, -0.1379],\n",
            "         [ 0.0686,  0.1972, -0.4168,  ..., -0.4170,  0.1846, -0.6656],\n",
            "         [ 0.4276, -0.2305,  0.1077,  ...,  0.2380, -0.2137,  0.0474],\n",
            "         ...,\n",
            "         [ 0.1043,  0.5676,  0.5119,  ..., -0.0086,  0.3456, -0.2461],\n",
            "         [-0.0204,  0.2828,  0.2973,  ..., -0.1763,  0.4748, -0.1159],\n",
            "         [-1.0386, -0.0246,  0.2202,  ..., -0.7409,  0.7659, -0.1688]]],\n",
            "       grad_fn=<NativeLayerNormBackward>) tensor([[-0.4052,  0.3214, -0.1383,  ...,  0.1096, -0.0389, -0.4436],\n",
            "        [-0.4715,  0.3722, -0.0445,  ..., -0.0279,  0.2083, -0.4213]],\n",
            "       grad_fn=<TanhBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nout (tensor([[-0.4694, -0.2888,  0.1584,  0.1443,  0.2474],\\n        [-0.4795, -0.2614,  0.0915,  0.1614,  0.1209]],\\n       grad_fn=<AddmmBackward>),)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdBsigqdB3ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 774
        },
        "outputId": "e27918a1-b020-480a-eb47-8fbdee1d06ff"
      },
      "source": [
        "import pickle\n",
        "import re\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_sequence, pad_packed_sequence, pad_sequence, pack_padded_sequence\n",
        "!pip install transformers\n",
        "!apt install git make curl xz-utils file\n",
        "!apt install mecab libmecab-dev mecab-ipadic mecab-ipadic-utf8\n",
        "!pip install mecab-python3==0.996.5\n",
        "\n",
        "#import torch\n",
        "from transformers import BertJapaneseTokenizer, BertForMaskedLM\n",
        "import transformers\n",
        "\n",
        "pretrained_model_name = 'cl-tohoku/bert-base-japanese-whole-word-masking'\n",
        "\n",
        "# 事前学習済みモデルのトークナイザを使用\n",
        "tokenizer = BertJapaneseTokenizer.from_pretrained(pretrained_model_name)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "make is already the newest version (4.1-9.1ubuntu1).\n",
            "xz-utils is already the newest version (5.2.2-1.3).\n",
            "curl is already the newest version (7.58.0-2ubuntu3.9).\n",
            "file is already the newest version (1:5.32-2ubuntu0.4).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.7).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "libmecab-dev is already the newest version (0.996-5).\n",
            "mecab is already the newest version (0.996-5).\n",
            "mecab-ipadic is already the newest version (2.7.0-20070801+main-1).\n",
            "mecab-ipadic-utf8 is already the newest version (2.7.0-20070801+main-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-440\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: mecab-python3==0.996.5 in /usr/local/lib/python3.6/dist-packages (0.996.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQt3semI4akT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6116a31f-47f3-45df-e18d-3653cf7e2694"
      },
      "source": [
        "import time\n",
        "def get_data(fname):\n",
        "    label_list = [] # ラベル(カテゴリーのid)を格納するリスト\n",
        "    ids_list = [] # タイトルに含まれる単語のID系列のtensorを格納するリスト\n",
        "\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.strip()\n",
        "            if len(line.split(\"\\t\")[1]) != 1:\n",
        "                continue\n",
        "                \n",
        "            title = line.split(\"\\t\")[0] #\n",
        "            ids_list.append(title) \n",
        "\n",
        "            label = line.split(\"\\t\")[1] \n",
        "            label = int(label) #str2intに\n",
        "            label_list.append(label) #\n",
        "    labels = torch.tensor(label_list) #label_listをtensorに変換 \n",
        "    return ids_list, labels\n",
        "\n",
        "class RnnDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, label):\n",
        "        self.for_bert_inputs = tokenizer(data, padding=True, return_tensors=\"pt\")\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.for_bert_inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.for_bert_inputs[\"input_ids\"][idx], self.for_bert_inputs[\"token_type_ids\"][idx], self.for_bert_inputs[\"attention_mask\"][idx], self.label[idx]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#vocab_size = max(word2id.values()) + 1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# データの準備\n",
        "train_path =  \"train.tsv\"#学習用ファイルパス\n",
        "train_x, train_y = get_data(train_path)\n",
        "valid_path = \"dev.tsv\"#todo 評価用ファイルパス\n",
        "valid_x, valid_y = get_data(valid_path)\n",
        "test_path = \"test.tsv\"\n",
        "test_x, test_y = get_data(test_path)\n",
        "\n",
        "#for_bert_inputs_valid = tokenizer(valid_x, padding=True, return_tensors=\"pt\")\n",
        "dataset = RnnDataset(train_x, train_y)\n",
        "validset = RnnDataset(valid_x, valid_y)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(validset, batch_size=batch_size)\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=7)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(model, train_loader):\n",
        "    s = time.time()\n",
        "    #print(1)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_num = 0\n",
        "    #i = 0\n",
        "    len_loader = len(train_loader) * batch_size\n",
        "    #print(len_loader)\n",
        "    print(len_loader)\n",
        "    for data, types, mask, target in train_loader:\n",
        "        # GPUへ\n",
        "        #print(len(target))\n",
        "        #i=i+batch_size\n",
        "        #print(i)\n",
        "        #print(data.shape)\n",
        "        #print(types.shape)\n",
        "        #print(mask.shape)\n",
        "        #print(target.shape)\n",
        "        data = data.to(device)\n",
        "        types = types.to(device)\n",
        "        mask = mask.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(input_ids=data, token_type_ids=types, attention_mask=mask) #返り値tuple型\n",
        "        pred = pred[0]\n",
        "        #print(pred)\n",
        "        #print(target)\n",
        "        #pred = torch.tensor(pred)\n",
        "        #print(pred.type, target.type)\n",
        "        loss = loss_fn(pred, target) #lossを計算\n",
        "        loss.backward() #逆伝播\n",
        "        optimizer.step()\n",
        "        #print(\"loss: \", loss)\n",
        "        total_loss+= loss.item() #lossをtotal_lossに加算\n",
        "        correct_num += (torch.argmax(pred, axis=1)==target).sum().item() #予測の正解数をカウント\n",
        "    batch_loss = total_loss/len(train_loader) #バッチごとの平均ロス\n",
        "    acc = correct_num/len_loader#todo 正解率\n",
        "    print(\"time: \", time.time()-s)\n",
        "    print(correct_num, len_loader)\n",
        "    return batch_loss, acc\n",
        "\n",
        "#for_bert_inputs_valid.to(device)\n",
        "#valid_y.to(device)\n",
        "\n",
        "def evaluation(model, valid_loader):\n",
        "    model.eval()\n",
        "    len_loader = len(valid_loader) * batch_size\n",
        "    #print(len_loader)\n",
        "    total_loss = 0\n",
        "    correct_num = 0\n",
        "    for data, types, mask, target in valid_loader:\n",
        "      data = data.to(device)\n",
        "      types = types.to(device)\n",
        "      mask = mask.to(device)\n",
        "      target = target.to(device)\n",
        "      with torch.no_grad():\n",
        "        pred = model(input_ids=data, token_type_ids=types, attention_mask=mask)#todo 予測\n",
        "        pred = pred[0]\n",
        "        #print(pred.type, target.type)\n",
        "        loss = loss_fn(pred, target)#todo 損失を計算\n",
        "        total_loss+= loss.item() #lossをtotal_lossに加算\n",
        "        correct_num += (torch.argmax(pred, axis=1)==target).sum().item() #予測の正解数をカウント\n",
        "      \n",
        "    batch_loss = total_loss/len(valid_loader)\n",
        "    acc = correct_num/len_loader#todo 正解率を計算\n",
        "    print(correct_num, len_loader)\n",
        "    return batch_loss, acc\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train(model, train_loader)\n",
        "    valid_loss, valid_acc = evaluation(model, valid_loader)\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    print(f\"<train> Loss: {train_loss}\\tAccuracy: {train_acc}\")\n",
        "    print(f\"<valid> Loss: {valid_loss}\\tAccuracy: {valid_acc}\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "67648\n",
            "time:  1208.2634394168854\n",
            "11411 67648\n",
            "275 2000\n",
            "epoch: 0\n",
            "<train> Loss: 2.1379557777206744\tAccuracy: 0.1686820009460738\n",
            "<valid> Loss: 2.0778386878967283\tAccuracy: 0.1375\n",
            "67648\n",
            "time:  1208.2819635868073\n",
            "12194 67648\n",
            "352 2000\n",
            "epoch: 1\n",
            "<train> Loss: 1.9361125639901482\tAccuracy: 0.1802566225165563\n",
            "<valid> Loss: 1.928663770675659\tAccuracy: 0.176\n",
            "67648\n",
            "time:  1208.3797116279602\n",
            "12835 67648\n",
            "422 2000\n",
            "epoch: 2\n",
            "<train> Loss: 1.9112069104060658\tAccuracy: 0.18973214285714285\n",
            "<valid> Loss: 1.909578621864319\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.4777405261993\n",
            "12954 67648\n",
            "422 2000\n",
            "epoch: 3\n",
            "<train> Loss: 1.9079353721387677\tAccuracy: 0.19149124881740776\n",
            "<valid> Loss: 1.9146439456939697\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.4466760158539\n",
            "13100 67648\n",
            "422 2000\n",
            "epoch: 4\n",
            "<train> Loss: 1.9061523226769104\tAccuracy: 0.19364947965941343\n",
            "<valid> Loss: 1.9201182765960694\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.4270915985107\n",
            "13203 67648\n",
            "422 2000\n",
            "epoch: 5\n",
            "<train> Loss: 1.904700327985334\tAccuracy: 0.19517206717123936\n",
            "<valid> Loss: 1.9119973764419556\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.3855185508728\n",
            "13118 67648\n",
            "422 2000\n",
            "epoch: 6\n",
            "<train> Loss: 1.9041138062977858\tAccuracy: 0.1939155629139073\n",
            "<valid> Loss: 1.9168354864120483\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.642594575882\n",
            "13340 67648\n",
            "422 2000\n",
            "epoch: 7\n",
            "<train> Loss: 1.9032069631590522\tAccuracy: 0.1971972563859981\n",
            "<valid> Loss: 1.9100283918380738\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.834520816803\n",
            "13314 67648\n",
            "422 2000\n",
            "epoch: 8\n",
            "<train> Loss: 1.9032362972720118\tAccuracy: 0.19681291390728478\n",
            "<valid> Loss: 1.9137588758468629\tAccuracy: 0.211\n",
            "67648\n",
            "time:  1208.573212146759\n",
            "13388 67648\n",
            "422 2000\n",
            "epoch: 9\n",
            "<train> Loss: 1.9028547855628022\tAccuracy: 0.19790681173131505\n",
            "<valid> Loss: 1.9110939998626708\tAccuracy: 0.211\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-bjUfAHBRtr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9412577-9ef6-4f4b-b111-d7cf57462dba"
      },
      "source": [
        "import time\n",
        "def get_data(fname):\n",
        "    label_list = [] # ラベル(カテゴリーのid)を格納するリスト\n",
        "    ids_list = [] # タイトルに含まれる単語のID系列のtensorを格納するリスト\n",
        "\n",
        "    with open(fname) as f:\n",
        "        for line in f:\n",
        "            if not line:\n",
        "                continue\n",
        "            line = line.strip()\n",
        "            if len(line.split(\"\\t\")[1]) != 1:\n",
        "                continue\n",
        "                \n",
        "            title = line.split(\"\\t\")[0] #\n",
        "            ids_list.append(title) \n",
        "\n",
        "            label = line.split(\"\\t\")[1] \n",
        "            label = int(label) #str2intに\n",
        "            label_list.append(label) #\n",
        "    labels = torch.tensor(label_list) #label_listをtensorに変換 \n",
        "    return ids_list, labels\n",
        "\n",
        "class RnnDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, label):\n",
        "        self.for_bert_inputs = tokenizer(data, padding=True, return_tensors=\"pt\")\n",
        "        self.label = label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.for_bert_inputs[\"input_ids\"])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.for_bert_inputs[\"input_ids\"][idx], self.for_bert_inputs[\"token_type_ids\"][idx], self.for_bert_inputs[\"attention_mask\"][idx], self.label[idx]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "#vocab_size = max(word2id.values()) + 1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# データの準備\n",
        "train_path =  \"train.tsv\"#学習用ファイルパス\n",
        "train_x, train_y = get_data(train_path)\n",
        "valid_path = \"dev.tsv\"#todo 評価用ファイルパス\n",
        "valid_x, valid_y = get_data(valid_path)\n",
        "test_path = \"test.tsv\"\n",
        "test_x, test_y = get_data(test_path)\n",
        "\n",
        "#for_bert_inputs_valid = tokenizer(valid_x, padding=True, return_tensors=\"pt\")\n",
        "dataset = RnnDataset(train_x, train_y)\n",
        "validset = RnnDataset(valid_x, valid_y)\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_loader = DataLoader(validset, batch_size=batch_size)\n",
        "model = transformers.BertForSequenceClassification.from_pretrained(pretrained_model_name, num_labels=7)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.05)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "def train(model, train_loader):\n",
        "    s = time.time()\n",
        "    #print(1)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct_num = 0\n",
        "    #i = 0\n",
        "    len_loader = len(train_loader) * batch_size\n",
        "    #print(len_loader)\n",
        "    print(len_loader)\n",
        "    for data, types, mask, target in train_loader:\n",
        "        # GPUへ\n",
        "        #print(len(target))\n",
        "        #i=i+batch_size\n",
        "        #print(i)\n",
        "        #print(data.shape)\n",
        "        #print(types.shape)\n",
        "        #print(mask.shape)\n",
        "        #print(target.shape)\n",
        "        data = data.to(device)\n",
        "        types = types.to(device)\n",
        "        mask = mask.to(device)\n",
        "        target = target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(input_ids=data, token_type_ids=types, attention_mask=mask) #返り値tuple型\n",
        "        pred = pred[0]\n",
        "        print(pred.shape)\n",
        "        #print(target)\n",
        "        #pred = torch.tensor(pred)\n",
        "        #print(pred.type, target.type)\n",
        "        loss = loss_fn(pred, target) #lossを計算\n",
        "        loss.backward() #逆伝播\n",
        "        optimizer.step()\n",
        "        print(\"loss: \", loss)\n",
        "        total_loss+= loss.item() #lossをtotal_lossに加算\n",
        "        correct_num += (torch.argmax(pred, axis=1)==target).sum().item() #予測の正解数をカウント\n",
        "    batch_loss = total_loss/len(train_loader) #バッチごとの平均ロス\n",
        "    acc = correct_num/len_loader#todo 正解率\n",
        "    print(\"time: \", time.time()-s)\n",
        "    print(correct_num, len_loader)\n",
        "    return batch_loss, acc\n",
        "\n",
        "#for_bert_inputs_valid.to(device)\n",
        "#valid_y.to(device)\n",
        "\n",
        "def evaluation(model, valid_loader):\n",
        "    model.eval()\n",
        "    len_loader = len(valid_loader) * batch_size\n",
        "    #print(len_loader)\n",
        "    total_loss = 0\n",
        "    correct_num = 0\n",
        "    for data, types, mask, target in valid_loader:\n",
        "      data = data.to(device)\n",
        "      types = types.to(device)\n",
        "      mask = mask.to(device)\n",
        "      target = target.to(device)\n",
        "      with torch.no_grad():\n",
        "        pred = model(input_ids=data, token_type_ids=types, attention_mask=mask)#todo 予測\n",
        "        pred = pred[0]\n",
        "        #print(pred.type, target.type)\n",
        "        loss = loss_fn(pred, target)#todo 損失を計算\n",
        "        total_loss+= loss.item() #lossをtotal_lossに加算\n",
        "        correct_num += (torch.argmax(pred, axis=1)==target).sum().item() #予測の正解数をカウント\n",
        "      \n",
        "    batch_loss = total_loss/len(valid_loader)\n",
        "    acc = correct_num/len_loader#todo 正解率を計算\n",
        "    print(correct_num, len_loader)\n",
        "    return batch_loss, acc\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_loss, train_acc = train(model, train_loader)\n",
        "    valid_loss, valid_acc = evaluation(model, valid_loader)\n",
        "    print(f\"epoch: {epoch}\")\n",
        "    print(f\"<train> Loss: {train_loss}\\tAccuracy: {train_acc}\")\n",
        "    print(f\"<valid> Loss: {valid_loss}\\tAccuracy: {valid_acc}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "67648\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.6887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.9046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.7509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(9.9993, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.0368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.5457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.3089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.1320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(10.7489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(6.7352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(10.4599, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.9407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(15.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(13.4620, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(6.0409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(8.3830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.8675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(8.4474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(14.1798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.3658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.4803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(6.8768, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.2340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.0116, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.9786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.8126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.5785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.8980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.7541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(7.6845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.4671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.3023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.3597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.1060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.6932, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.5192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.8287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(8.1568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.5032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.9830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.6088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.5729, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.2079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.0816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.8154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.3253, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.6534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(7.8856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.9989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.5649, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0283, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2258, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1564, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9286, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0648, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9332, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2295, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8041, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0699, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7876, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8864, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9245, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8641, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1763, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0355, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8791, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9974, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3102, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1030, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9714, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7727, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8424, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0966, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9646, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7450, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9967, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8210, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.6138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9916, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8977, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9317, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8988, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.0021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.4596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.8137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.2216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(8.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.4090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2613, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.4328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.0845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7735, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.0193, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.5013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.4079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.3587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.3918, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(5.2738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.7445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9898, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.5312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(4.0384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(3.2813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3998, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.7092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.6566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.6133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8449, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.5158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8498, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.4299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8569, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7835, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0308, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0664, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0082, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9653, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8813, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9393, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0364, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8479, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.5893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.3221, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0961, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9257, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8621, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9883, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9177, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8512, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9721, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8439, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8693, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7903, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9626, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1738, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8261, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8655, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8689, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8001, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7980, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8519, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8021, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9762, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8928, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8907, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9745, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8489, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0887, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8555, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0537, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0556, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9318, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8500, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9218, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9552, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9179, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9853, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1153, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8696, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8242, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8744, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7757, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0196, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9636, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0415, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9734, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0434, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9733, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9560, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9754, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9353, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8416, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8492, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7979, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9483, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9297, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8376, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9542, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9516, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0281, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9198, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8577, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9276, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0034, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1547, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9507, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9108, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0400, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8201, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8438, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8959, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9692, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8878, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8934, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9787, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9379, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7972, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9062, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9764, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8817, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8505, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9239, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9410, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9302, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9550, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8413, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7885, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9188, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7371, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8328, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9535, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9945, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9204, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8840, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9208, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9821, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9387, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8877, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8402, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8397, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0327, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8533, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8695, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9508, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9040, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9127, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9380, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8797, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8816, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8850, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7941, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0190, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8150, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8851, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9087, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9407, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9749, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9433, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7341, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9390, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9504, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9627, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8920, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9213, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9471, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9186, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9825, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9305, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8658, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9796, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8779, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1100, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8583, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9289, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9581, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9899, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8522, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0016, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8973, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9366, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8089, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9057, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9663, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9099, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7902, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8820, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7786, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8772, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9563, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9460, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7975, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8987, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9333, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9360, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8849, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1054, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8517, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9025, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8477, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8440, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9378, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9036, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9132, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0237, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8430, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9888, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8933, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9423, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9725, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8954, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9618, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8752, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8847, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0163, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8940, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9084, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9026, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8778, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9694, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0671, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0312, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8546, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0785, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8527, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8782, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8432, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7502, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9417, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9373, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9551, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8311, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8083, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0010, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9005, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9566, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8775, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8917, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7474, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9090, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9063, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8957, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7897, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9350, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9320, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9316, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7741, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0167, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8139, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9075, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8456, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8361, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9226, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8377, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1049, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8568, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8743, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8949, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9412, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0287, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9386, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9645, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8698, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8112, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8852, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0195, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7461, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9055, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8326, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9028, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7832, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9370, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8588, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7846, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7548, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8773, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7758, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7587, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8767, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0007, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8071, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0589, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9042, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8617, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0608, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8985, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9685, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9032, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8506, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8578, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8161, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8776, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9777, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9567, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1002, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9700, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9697, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8837, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9228, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0605, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8319, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9052, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0035, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7737, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9862, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8770, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1231, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9867, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8147, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8935, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9881, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9294, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8684, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9120, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9381, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0375, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9860, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9872, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9331, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8363, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8325, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8027, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9155, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8812, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8254, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7044, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8475, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7976, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9033, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9869, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9164, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9248, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7811, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8596, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9428, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9925, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9157, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9135, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8906, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8249, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9182, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8138, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8435, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8148, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8702, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7252, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8110, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8911, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9398, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8151, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9711, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8322, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0789, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8662, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9191, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9050, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1314, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9203, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0000, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9209, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9514, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8584, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9233, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0346, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8926, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8518, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8927, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8215, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9227, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0241, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9944, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8553, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8534, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8651, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8554, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9890, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8462, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8936, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0122, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9313, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8592, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0091, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8722, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8426, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8751, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8805, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0688, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9192, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9126, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0833, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8372, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0345, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9602, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8624, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9425, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8642, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9488, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9670, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9158, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9742, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8384, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0436, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8607, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8669, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9267, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8808, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9672, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9524, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8750, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8523, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7225, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9794, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9159, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9272, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8497, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8631, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9269, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8334, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0194, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9056, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1422, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8637, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8724, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9561, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8310, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9431, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9037, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0543, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8827, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8844, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8984, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7235, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0391, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9262, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8955, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8822, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9008, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8803, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8838, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8526, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0130, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9875, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9068, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8912, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8947, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0097, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8834, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9541, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8982, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8657, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9437, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7958, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9889, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8992, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8369, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7278, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0128, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8576, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8622, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9292, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9644, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9715, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9299, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0650, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9392, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9676, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0078, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0452, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8356, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8848, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8632, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9494, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8963, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8104, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8703, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8268, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8092, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9549, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9170, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8760, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7968, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0076, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9748, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8223, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9739, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8051, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0171, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9014, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9175, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8880, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9628, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8206, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8731, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8134, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9154, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8656, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0999, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9343, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9408, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8810, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9029, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8809, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7571, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8683, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0723, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9230, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0019, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8222, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8960, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9421, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8765, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9080, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9710, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8162, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8088, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7819, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9654, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8611, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8591, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0704, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9106, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0214, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9185, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0107, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9484, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9863, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8251, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8709, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8799, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0020, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9501, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9220, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8465, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8216, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8129, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9285, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9659, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9212, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9256, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8125, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9053, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8493, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9719, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9582, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8708, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9472, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8388, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8823, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8229, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0800, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8630, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8873, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8771, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8678, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7922, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9989, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8793, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8774, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9038, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9503, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8824, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9404, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9101, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8496, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9532, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9411, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8804, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8374, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9389, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0828, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8894, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0074, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0528, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9478, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9509, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8806, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8481, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8924, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7964, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9069, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9718, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9766, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8095, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9011, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0921, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8713, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8753, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8357, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9160, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9022, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9845, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9491, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8795, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8784, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8123, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9207, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8347, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8717, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8629, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8855, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9232, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8451, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9447, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8929, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8236, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7857, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8093, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7829, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0003, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9445, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7909, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8712, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8603, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8639, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9612, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8443, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9146, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8117, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7905, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0149, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8675, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8886, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8338, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8572, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7499, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8705, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0562, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.6995, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9585, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9559, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9274, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9073, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9814, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7224, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7900, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.2114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8891, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8539, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7756, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7780, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9540, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8459, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0931, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8625, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1520, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9746, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9544, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8815, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9180, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9365, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9015, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8874, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8595, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9792, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8953, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9570, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9137, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9321, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9677, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9615, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9673, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8879, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9293, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9579, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9382, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9904, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8219, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9259, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8181, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0901, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9077, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8997, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8121, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9395, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8681, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7868, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8896, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8536, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8403, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9557, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8187, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8598, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8759, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0668, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8453, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9058, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8830, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9565, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9031, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8490, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8842, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7623, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0144, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0996, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8309, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9133, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8946, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9094, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7991, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9340, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8856, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7914, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9264, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9638, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8666, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0580, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8530, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8511, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9788, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9515, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8217, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9298, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9861, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9359, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8394, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7895, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8263, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0086, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8597, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9199, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9255, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9169, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8419, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9635, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9682, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9234, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9716, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9604, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9470, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0271, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9246, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8307, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8414, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8728, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9476, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7633, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0176, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9680, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8525, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9260, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9296, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8601, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8290, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8574, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9047, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9023, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0726, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0017, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9342, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0367, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9487, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9140, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8085, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8330, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.1064, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9486, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9124, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8983, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8466, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8351, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0284, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8802, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9060, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9358, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9790, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7919, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0344, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0012, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0303, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8480, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9238, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8884, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9441, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9674, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9273, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8323, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9455, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8915, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9893, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9348, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8409, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8473, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9300, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9866, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9109, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9865, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8783, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8826, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0329, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9145, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9288, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8266, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8096, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8385, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9956, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9061, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8948, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9707, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(2.0006, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9114, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9529, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8801, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9690, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9306, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8942, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9429, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.7938, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9913, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9205, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8240, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.8468, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9586, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9131, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9442, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9352, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n",
            "loss:  tensor(1.9798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
            "torch.Size([16, 7])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-b51360d2b6fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch: {epoch}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-b51360d2b6fd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;31m#print(pred.type, target.type)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#lossを計算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#逆伝播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loss: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2LaCF9n1kTn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}