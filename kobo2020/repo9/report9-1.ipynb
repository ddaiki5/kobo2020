{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXlgha4RkbIO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "431d20c1-f9dd-456e-e47e-73a945fbd9bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dir_path = '/content/drive/My Drive/Colab Notebooks'\n",
        "import os\n",
        "os.chdir(dir_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl-a7d6gluq_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7edc540e-92e0-424c-c1dd-27e190262e02"
      },
      "source": [
        "import gensim\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "w2v_path = 'GoogleNews-vectors-negative300.bin (1).gz'\n",
        "data_path = 'report8/data70/'\n",
        "\n",
        "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(w2v_path , binary=True)\n",
        "\n",
        "category2num = {\"b\": 0, \"t\": 1, \"e\": 2, \"m\": 3}"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:254: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM82ITmWmF0l",
        "colab_type": "text"
      },
      "source": [
        "70"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce91aTY-l15c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# タイトルを受け取り，単語ベクトルの平均を返す関数\n",
        "def get_feature(title):\n",
        "    word_list = title.split(' ')#todo タイトルをスペースで分割\n",
        "    vec_list = []\n",
        "    for word in word_list:\n",
        "        try:\n",
        "            vec = w2v_model[word]#todo wordを意味するベクトルを取得\n",
        "        except KeyError:\n",
        "            vec = np.zeros(300)#todo すべての要素が0のベクトルを代入\n",
        "        vec_list.append(vec)    \n",
        "    vec_np = np.array(vec_list) # numpyのarrayに変換\n",
        "    feature = np.sum(vec_np, axis=0)/len(vec_np)# 平均ベクトルを計算\n",
        "    return feature\n",
        "\n",
        "\n",
        "def get_data(fname):\n",
        "    label_list = []\n",
        "    feature_list = []\n",
        "    with open(fname, encoding=\"utf8\") as f:\n",
        "        for line in f:\n",
        "            if not line:\n",
        "                continue\n",
        "            data = line.split('\\t')\n",
        "            title = data[1]#todo dataからタイトルを取り出す\n",
        "            feature = get_feature(title) \n",
        "            feature_list.append(feature)\n",
        "            label = category2num[data[0]]\n",
        "            label_list.append(label)\n",
        "\n",
        "    features = torch.tensor(feature_list)#todo feature_listをtensorに変換\n",
        "    labels = torch.tensor(label_list)#todo label_listをtensorに変換\n",
        "    return features, labels\n",
        "\n",
        "\n",
        "train_x, train_y = get_data(data_path + \"train.txt\")\n",
        "valid_x, valid_y = get_data(data_path + \"valid.txt\")\n",
        "test_x, test_y = get_data(data_path + \"test.txt\")\n",
        "\n",
        "# 保存\n",
        "torch.save(train_x, data_path + \"train_x.pt\")\n",
        "torch.save(train_y, data_path + \"train_y.pt\")\n",
        "torch.save(valid_x, data_path + \"valid_x.pt\")\n",
        "torch.save(valid_y, data_path + \"valid_y.pt\")\n",
        "torch.save(test_x, data_path + \"test_x.pt\")\n",
        "torch.save(test_y, data_path + \"test_y.pt\")"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_62Zv15mlQGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "78a8a404-3133-4a92-c9d1-3e5f3690ebff"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import time\n",
        "\n",
        "# 単層ニューラルネットワークを定義\n",
        "class SingleLayerNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, num_labels):\n",
        "        super(SingleLayerNN, self).__init__()\n",
        "        self.linear = nn.Linear(embedding_dim, num_labels) #todo linear層を追加 4次元の結果が帰ってくる\n",
        "    \n",
        "    def forward(self, x):\n",
        "        h1 = self.linear(x)#todo xをlinear層に入力\n",
        "        softmax = nn.Softmax()\n",
        "        return softmax(h1) #todo h1をsoftmaxしたものを返す\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)  #todo データサイズを返す\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        out_x = self.x[idx]#todo idx番目のxの要素を返す\n",
        "        out_y = self.y[idx]#todo idx番目のyの要素を返す\n",
        "        return out_x, out_y\n",
        "        \n",
        "torch.manual_seed(1)\n",
        "\n",
        "embedding_dim = 300\n",
        "num_labels = 4\n",
        "NUM_EPOCH = 100\n",
        "\n",
        "train_x, train_y = torch.load(\"./report8/data70/train_x.pt\"), torch.load(\"./report8/data70/train_y.pt\")\n",
        "valid_x, valid_y = torch.load(\"./report8/data70/valid_x.pt\"), torch.load(\"./report8/data70/valid_y.pt\")\n",
        "\n",
        "\n",
        "# データとラベルを1つにまとめる\n",
        "dataset = MyDataset(train_x, train_y)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()#todo 損失関数としてCrossEntropyLossを用いる\n",
        "\n",
        "\n",
        "def train(model, train_loader):\n",
        "    model.train()\n",
        "    for data, target in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        pred = model(data.type(torch.FloatTensor))#todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)#todo predとtargetと損失関数からロスを計算\n",
        "        loss.backward() # 逆誤差伝搬を実施\n",
        "        optimizer.step() # パラメータを更新\n",
        "\n",
        "\n",
        "def evaluation(model, data, target):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred = model.forward(data.type(torch.FloatTensor))#todo dataをmodelに入力\n",
        "        loss = loss_fn(pred, target)#todo predとtargetと損失関数からロスを計算\n",
        "        pred_labels = torch.argmax(pred, axis=1)#todo 推定したラベルを代入　どの次元が一番確率が高いか　max\n",
        "        acc = (pred_labels==target).sum().item()/len(pred_labels)#todo pred_labelsとtargetから正解率を計算\n",
        "    return loss.item(), acc\n",
        "\n",
        "\n",
        "batch_size_list = [2**x for x in range(11)]#todo バッチサイズの値のリスト．1,2,4,8,…が入る\n",
        "\n",
        "\n",
        "for batch_size in batch_size_list:\n",
        "    model = SingleLayerNN(embedding_dim, num_labels)\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
        "\n",
        "    # ミニバッチを扱うためのデータローダを作成\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    for epoch in range(NUM_EPOCH):\n",
        "        start_time = time.time() # 学習開始時の時間を取得\n",
        "        train(model, train_loader)\n",
        "        took_time = time.time() - start_time #todo 学習にかかった時間を代入\n",
        "        #print(valid_y)\n",
        "        valid_loss, valid_acc = evaluation(model, valid_x, valid_y)\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"batch size:{batch_size}\\tepoch: {epoch}\")\n",
        "            print(f\"train time: {took_time}\")\n",
        "            print(f\"<valid>\\tloss: {valid_loss}\\tacc: {valid_acc}\")\n",
        "    \n",
        "    print(\"\\n================\\n\")\n"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "batch size:1\tepoch: 0\n",
            "train time: 5.432270288467407\n",
            "<valid>\tloss: 0.9587206244468689\tacc: 0.800599700149925\n",
            "batch size:1\tepoch: 10\n",
            "train time: 5.3603832721710205\n",
            "<valid>\tloss: 0.9397221803665161\tacc: 0.8013493253373314\n",
            "batch size:1\tepoch: 20\n",
            "train time: 5.406141519546509\n",
            "<valid>\tloss: 0.9378631114959717\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 30\n",
            "train time: 5.465374946594238\n",
            "<valid>\tloss: 0.936996340751648\tacc: 0.8035982008995503\n",
            "batch size:1\tepoch: 40\n",
            "train time: 5.5977911949157715\n",
            "<valid>\tloss: 0.9364750981330872\tacc: 0.802848575712144\n",
            "batch size:1\tepoch: 50\n",
            "train time: 5.488953113555908\n",
            "<valid>\tloss: 0.9360454082489014\tacc: 0.8020989505247377\n",
            "batch size:1\tepoch: 60\n",
            "train time: 5.544880390167236\n",
            "<valid>\tloss: 0.8930370211601257\tacc: 0.8538230884557722\n",
            "batch size:1\tepoch: 70\n",
            "train time: 5.4050493240356445\n",
            "<valid>\tloss: 0.8867973685264587\tacc: 0.8590704647676162\n",
            "batch size:1\tepoch: 80\n",
            "train time: 5.4647557735443115\n",
            "<valid>\tloss: 0.8853724002838135\tacc: 0.8598200899550225\n",
            "batch size:1\tepoch: 90\n",
            "train time: 5.3810412883758545\n",
            "<valid>\tloss: 0.8844170570373535\tacc: 0.8620689655172413\n",
            "\n",
            "================\n",
            "\n",
            "batch size:2\tepoch: 0\n",
            "train time: 2.872767686843872\n",
            "<valid>\tloss: 0.9724141359329224\tacc: 0.8020989505247377\n",
            "batch size:2\tepoch: 10\n",
            "train time: 2.748441457748413\n",
            "<valid>\tloss: 0.9423859119415283\tacc: 0.7998500749625187\n",
            "batch size:2\tepoch: 20\n",
            "train time: 2.9606716632843018\n",
            "<valid>\tloss: 0.9398484230041504\tacc: 0.800599700149925\n",
            "batch size:2\tepoch: 30\n",
            "train time: 2.8878061771392822\n",
            "<valid>\tloss: 0.9385116100311279\tacc: 0.8035982008995503\n",
            "batch size:2\tepoch: 40\n",
            "train time: 2.7655107975006104\n",
            "<valid>\tloss: 0.9378167986869812\tacc: 0.8043478260869565\n",
            "batch size:2\tepoch: 50\n",
            "train time: 3.1014487743377686\n",
            "<valid>\tloss: 0.9373283386230469\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 60\n",
            "train time: 2.8368072509765625\n",
            "<valid>\tloss: 0.9369872212409973\tacc: 0.8058470764617691\n",
            "batch size:2\tepoch: 70\n",
            "train time: 2.948007583618164\n",
            "<valid>\tloss: 0.9366870522499084\tacc: 0.8050974512743628\n",
            "batch size:2\tepoch: 80\n",
            "train time: 2.949589490890503\n",
            "<valid>\tloss: 0.9364578127861023\tacc: 0.8065967016491754\n",
            "batch size:2\tepoch: 90\n",
            "train time: 2.961073637008667\n",
            "<valid>\tloss: 0.9362329840660095\tacc: 0.8058470764617691\n",
            "\n",
            "================\n",
            "\n",
            "batch size:4\tepoch: 0\n",
            "train time: 1.45768404006958\n",
            "<valid>\tloss: 0.9951785206794739\tacc: 0.7976011994002998\n",
            "batch size:4\tepoch: 10\n",
            "train time: 1.4657196998596191\n",
            "<valid>\tloss: 0.9468162059783936\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 20\n",
            "train time: 1.430016040802002\n",
            "<valid>\tloss: 0.9426440596580505\tacc: 0.7983508245877061\n",
            "batch size:4\tepoch: 30\n",
            "train time: 1.4706387519836426\n",
            "<valid>\tloss: 0.9408411979675293\tacc: 0.8013493253373314\n",
            "batch size:4\tepoch: 40\n",
            "train time: 1.4859426021575928\n",
            "<valid>\tloss: 0.9399241209030151\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 50\n",
            "train time: 1.5376908779144287\n",
            "<valid>\tloss: 0.9391137361526489\tacc: 0.800599700149925\n",
            "batch size:4\tepoch: 60\n",
            "train time: 1.4700703620910645\n",
            "<valid>\tloss: 0.9385632276535034\tacc: 0.8035982008995503\n",
            "batch size:4\tepoch: 70\n",
            "train time: 1.4263596534729004\n",
            "<valid>\tloss: 0.9381746649742126\tacc: 0.8043478260869565\n",
            "batch size:4\tepoch: 80\n",
            "train time: 1.4433684349060059\n",
            "<valid>\tloss: 0.9379227757453918\tacc: 0.8020989505247377\n",
            "batch size:4\tepoch: 90\n",
            "train time: 1.4455673694610596\n",
            "<valid>\tloss: 0.9375887513160706\tacc: 0.8050974512743628\n",
            "\n",
            "================\n",
            "\n",
            "batch size:8\tepoch: 0\n",
            "train time: 0.7743682861328125\n",
            "<valid>\tloss: 1.0347410440444946\tacc: 0.7938530734632684\n",
            "batch size:8\tepoch: 10\n",
            "train time: 0.9081382751464844\n",
            "<valid>\tloss: 0.9539514183998108\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 20\n",
            "train time: 0.7842943668365479\n",
            "<valid>\tloss: 0.9472652673721313\tacc: 0.800599700149925\n",
            "batch size:8\tepoch: 30\n",
            "train time: 0.7512874603271484\n",
            "<valid>\tloss: 0.9444462060928345\tacc: 0.7998500749625187\n",
            "batch size:8\tepoch: 40\n",
            "train time: 0.7790944576263428\n",
            "<valid>\tloss: 0.9428423643112183\tacc: 0.7991004497751124\n",
            "batch size:8\tepoch: 50\n",
            "train time: 0.7671589851379395\n",
            "<valid>\tloss: 0.9417800307273865\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 60\n",
            "train time: 0.7540082931518555\n",
            "<valid>\tloss: 0.9409576654434204\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 70\n",
            "train time: 0.7560267448425293\n",
            "<valid>\tloss: 0.9403571486473083\tacc: 0.8020989505247377\n",
            "batch size:8\tepoch: 80\n",
            "train time: 0.8079431056976318\n",
            "<valid>\tloss: 0.9398747682571411\tacc: 0.8013493253373314\n",
            "batch size:8\tepoch: 90\n",
            "train time: 0.8039076328277588\n",
            "<valid>\tloss: 0.9394803047180176\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:16\tepoch: 0\n",
            "train time: 0.4190678596496582\n",
            "<valid>\tloss: 1.096767544746399\tacc: 0.7938530734632684\n",
            "batch size:16\tepoch: 10\n",
            "train time: 0.4058351516723633\n",
            "<valid>\tloss: 0.9651311039924622\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 20\n",
            "train time: 0.4298889636993408\n",
            "<valid>\tloss: 0.9545049071311951\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 30\n",
            "train time: 0.44594430923461914\n",
            "<valid>\tloss: 0.9499592185020447\tacc: 0.8013493253373314\n",
            "batch size:16\tepoch: 40\n",
            "train time: 0.4723777770996094\n",
            "<valid>\tloss: 0.9473902583122253\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 50\n",
            "train time: 0.4638185501098633\n",
            "<valid>\tloss: 0.9456802010536194\tacc: 0.7998500749625187\n",
            "batch size:16\tepoch: 60\n",
            "train time: 0.4765603542327881\n",
            "<valid>\tloss: 0.9444577097892761\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 70\n",
            "train time: 0.47522473335266113\n",
            "<valid>\tloss: 0.9435298442840576\tacc: 0.800599700149925\n",
            "batch size:16\tepoch: 80\n",
            "train time: 0.41478896141052246\n",
            "<valid>\tloss: 0.9427953958511353\tacc: 0.7991004497751124\n",
            "batch size:16\tepoch: 90\n",
            "train time: 0.4228041172027588\n",
            "<valid>\tloss: 0.9421961307525635\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:32\tepoch: 0\n",
            "train time: 0.25310659408569336\n",
            "<valid>\tloss: 1.1795045137405396\tacc: 0.7901049475262368\n",
            "batch size:32\tepoch: 10\n",
            "train time: 0.2890627384185791\n",
            "<valid>\tloss: 0.9833818674087524\tacc: 0.7976011994002998\n",
            "batch size:32\tepoch: 20\n",
            "train time: 0.291548490524292\n",
            "<valid>\tloss: 0.9660875201225281\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 30\n",
            "train time: 0.25498533248901367\n",
            "<valid>\tloss: 0.9589011073112488\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 40\n",
            "train time: 0.2460482120513916\n",
            "<valid>\tloss: 0.954802393913269\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 50\n",
            "train time: 0.24125885963439941\n",
            "<valid>\tloss: 0.9520991444587708\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 60\n",
            "train time: 0.24361562728881836\n",
            "<valid>\tloss: 0.9501587152481079\tacc: 0.7998500749625187\n",
            "batch size:32\tepoch: 70\n",
            "train time: 0.24190521240234375\n",
            "<valid>\tloss: 0.9486894011497498\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 80\n",
            "train time: 0.2454051971435547\n",
            "<valid>\tloss: 0.9475265145301819\tacc: 0.800599700149925\n",
            "batch size:32\tepoch: 90\n",
            "train time: 0.24287772178649902\n",
            "<valid>\tloss: 0.946584165096283\tacc: 0.800599700149925\n",
            "\n",
            "================\n",
            "\n",
            "batch size:64\tepoch: 0\n",
            "train time: 0.16393327713012695\n",
            "<valid>\tloss: 1.252986192703247\tacc: 0.7721139430284858\n",
            "batch size:64\tepoch: 10\n",
            "train time: 0.1569371223449707\n",
            "<valid>\tloss: 1.013858675956726\tacc: 0.795352323838081\n",
            "batch size:64\tepoch: 20\n",
            "train time: 0.16750860214233398\n",
            "<valid>\tloss: 0.9849323034286499\tacc: 0.7983508245877061\n",
            "batch size:64\tepoch: 30\n",
            "train time: 0.16009092330932617\n",
            "<valid>\tloss: 0.9731804132461548\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 40\n",
            "train time: 0.18448495864868164\n",
            "<valid>\tloss: 0.966571033000946\tacc: 0.7991004497751124\n",
            "batch size:64\tepoch: 50\n",
            "train time: 0.15573954582214355\n",
            "<valid>\tloss: 0.9622400999069214\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 60\n",
            "train time: 0.15729379653930664\n",
            "<valid>\tloss: 0.9591432213783264\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 70\n",
            "train time: 0.15938591957092285\n",
            "<valid>\tloss: 0.9568002223968506\tacc: 0.800599700149925\n",
            "batch size:64\tepoch: 80\n",
            "train time: 0.15696334838867188\n",
            "<valid>\tloss: 0.9549495577812195\tacc: 0.7998500749625187\n",
            "batch size:64\tepoch: 90\n",
            "train time: 0.1886732578277588\n",
            "<valid>\tloss: 0.9534493684768677\tacc: 0.8013493253373314\n",
            "\n",
            "================\n",
            "\n",
            "batch size:128\tepoch: 0\n",
            "train time: 0.12034058570861816\n",
            "<valid>\tloss: 1.3098851442337036\tacc: 0.7796101949025487\n",
            "batch size:128\tepoch: 10\n",
            "train time: 0.11640644073486328\n",
            "<valid>\tloss: 1.0640039443969727\tacc: 0.7938530734632684\n",
            "batch size:128\tepoch: 20\n",
            "train time: 0.12822794914245605\n",
            "<valid>\tloss: 1.0162028074264526\tacc: 0.795352323838081\n",
            "batch size:128\tepoch: 30\n",
            "train time: 0.11911916732788086\n",
            "<valid>\tloss: 0.996565580368042\tacc: 0.7976011994002998\n",
            "batch size:128\tepoch: 40\n",
            "train time: 0.11950278282165527\n",
            "<valid>\tloss: 0.9856399893760681\tacc: 0.7983508245877061\n",
            "batch size:128\tepoch: 50\n",
            "train time: 0.13164329528808594\n",
            "<valid>\tloss: 0.9785651564598083\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 60\n",
            "train time: 0.12294244766235352\n",
            "<valid>\tloss: 0.9735413193702698\tacc: 0.7998500749625187\n",
            "batch size:128\tepoch: 70\n",
            "train time: 0.11925935745239258\n",
            "<valid>\tloss: 0.9697608947753906\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 80\n",
            "train time: 0.11897850036621094\n",
            "<valid>\tloss: 0.966791570186615\tacc: 0.7991004497751124\n",
            "batch size:128\tepoch: 90\n",
            "train time: 0.11779046058654785\n",
            "<valid>\tloss: 0.9643874168395996\tacc: 0.7998500749625187\n",
            "\n",
            "================\n",
            "\n",
            "batch size:256\tepoch: 0\n",
            "train time: 0.10142087936401367\n",
            "<valid>\tloss: 1.3434481620788574\tacc: 0.676911544227886\n",
            "batch size:256\tepoch: 10\n",
            "train time: 0.09750628471374512\n",
            "<valid>\tloss: 1.1388838291168213\tacc: 0.7901049475262368\n",
            "batch size:256\tepoch: 20\n",
            "train time: 0.09679627418518066\n",
            "<valid>\tloss: 1.0688270330429077\tacc: 0.7916041979010495\n",
            "batch size:256\tepoch: 30\n",
            "train time: 0.09624981880187988\n",
            "<valid>\tloss: 1.036470890045166\tacc: 0.7923538230884558\n",
            "batch size:256\tepoch: 40\n",
            "train time: 0.0969853401184082\n",
            "<valid>\tloss: 1.0180315971374512\tacc: 0.7946026986506747\n",
            "batch size:256\tepoch: 50\n",
            "train time: 0.09790897369384766\n",
            "<valid>\tloss: 1.0060709714889526\tacc: 0.7961019490254873\n",
            "batch size:256\tepoch: 60\n",
            "train time: 0.09771871566772461\n",
            "<valid>\tloss: 0.9976276755332947\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 70\n",
            "train time: 0.10154938697814941\n",
            "<valid>\tloss: 0.9913042783737183\tacc: 0.7968515742128935\n",
            "batch size:256\tepoch: 80\n",
            "train time: 0.10153365135192871\n",
            "<valid>\tloss: 0.9863716959953308\tacc: 0.7976011994002998\n",
            "batch size:256\tepoch: 90\n",
            "train time: 0.10323095321655273\n",
            "<valid>\tloss: 0.9824001789093018\tacc: 0.7976011994002998\n",
            "\n",
            "================\n",
            "\n",
            "batch size:512\tepoch: 0\n",
            "train time: 0.09025096893310547\n",
            "<valid>\tloss: 1.3584065437316895\tacc: 0.4737631184407796\n",
            "batch size:512\tepoch: 10\n",
            "train time: 0.09057736396789551\n",
            "<valid>\tloss: 1.218245029449463\tacc: 0.7833583208395802\n",
            "batch size:512\tepoch: 20\n",
            "train time: 0.08387160301208496\n",
            "<valid>\tloss: 1.1433475017547607\tacc: 0.7916041979010495\n",
            "batch size:512\tepoch: 30\n",
            "train time: 0.08686375617980957\n",
            "<valid>\tloss: 1.098671555519104\tacc: 0.7923538230884558\n",
            "batch size:512\tepoch: 40\n",
            "train time: 0.08372735977172852\n",
            "<valid>\tloss: 1.0702648162841797\tacc: 0.7931034482758621\n",
            "batch size:512\tepoch: 50\n",
            "train time: 0.08480143547058105\n",
            "<valid>\tloss: 1.0509202480316162\tacc: 0.7931034482758621\n",
            "batch size:512\tepoch: 60\n",
            "train time: 0.08368062973022461\n",
            "<valid>\tloss: 1.0369625091552734\tacc: 0.7938530734632684\n",
            "batch size:512\tepoch: 70\n",
            "train time: 0.08493185043334961\n",
            "<valid>\tloss: 1.026411771774292\tacc: 0.795352323838081\n",
            "batch size:512\tepoch: 80\n",
            "train time: 0.0872652530670166\n",
            "<valid>\tloss: 1.0181546211242676\tacc: 0.795352323838081\n",
            "batch size:512\tepoch: 90\n",
            "train time: 0.08385872840881348\n",
            "<valid>\tloss: 1.0114991664886475\tacc: 0.795352323838081\n",
            "\n",
            "================\n",
            "\n",
            "batch size:1024\tepoch: 0\n",
            "train time: 0.08249688148498535\n",
            "<valid>\tloss: 1.3794910907745361\tacc: 0.41904047976011993\n",
            "batch size:1024\tepoch: 10\n",
            "train time: 0.0836186408996582\n",
            "<valid>\tloss: 1.285961627960205\tacc: 0.7511244377811095\n",
            "batch size:1024\tepoch: 20\n",
            "train time: 0.08122420310974121\n",
            "<valid>\tloss: 1.2233905792236328\tacc: 0.7886056971514243\n",
            "batch size:1024\tepoch: 30\n",
            "train time: 0.08506274223327637\n",
            "<valid>\tloss: 1.1778899431228638\tacc: 0.7916041979010495\n",
            "batch size:1024\tepoch: 40\n",
            "train time: 0.08573770523071289\n",
            "<valid>\tloss: 1.143635630607605\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 50\n",
            "train time: 0.0921173095703125\n",
            "<valid>\tloss: 1.1175342798233032\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 60\n",
            "train time: 0.07855868339538574\n",
            "<valid>\tloss: 1.0972718000411987\tacc: 0.7923538230884558\n",
            "batch size:1024\tepoch: 70\n",
            "train time: 0.08258891105651855\n",
            "<valid>\tloss: 1.08124577999115\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 80\n",
            "train time: 0.08524703979492188\n",
            "<valid>\tloss: 1.0683377981185913\tacc: 0.7931034482758621\n",
            "batch size:1024\tepoch: 90\n",
            "train time: 0.08902692794799805\n",
            "<valid>\tloss: 1.0577130317687988\tacc: 0.7931034482758621\n",
            "\n",
            "================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8eJXdBPbql8",
        "colab_type": "text"
      },
      "source": [
        "バッチ１のとき後半で値が飛ぶところがあったが、それ以外は順調に学習できた。"
      ]
    }
  ]
}